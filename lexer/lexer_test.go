package lexer

import (
	"testing"

	"github.com/s-li1/interpreter/token"
)

func TestNextToken(t *testing.T) {
  input := `=+(){},;`

  tests := []struct {
    expectType token.TokenType
    expectedLiteral string
  } {
    {token.ASSIGN, "="},
    {token.PLUS, "+"},
    {token.LPAREN, "("},
    {token.RPAREN, ")"}, 
    {token.LBRACE, "{"},
    {token.RBRACE, "}"},
    {token.COMMA, ","}, 
    {token.SEMICOLON, ";"},
    {token.EOF, ""},
  } 

  l := New(input)

  for i, tt := range tests {
    tok := l.NextToken()

    if tok.Type != tt.expectType {
      t.Fatalf("tests [%d] - token type wrong. expected=%q, got %q", i, tt.expectType, tok.Type)
    }

    if tok.Literal != tt.expectedLiteral {
      t.Fatalf("tests [%d] - literal wrong. expected=%q, got %q", i, tt.expectedLiteral, tok.Literal)
    }
  }
}
